#Week 03 - Instance-Based Methods and Tree-Based Methods

Decision Tree Regression and Classification

Decision Trees are a type of supervised learning algorithm that can be used for both regression and classification tasks. They work by recursively splitting the data into subsets based on the value of input features, creating a tree-like model of decisions. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the features of the data. Decision Trees are easy to interpret and can handle both numerical and categorical data.

k-NN Regression and Classification

k-Nearest Neighbors (k-NN) is an instance-based learning algorithm that can be used for both regression and classification tasks. It works by finding the 'k' most similar instances (neighbors) in the training data to make predictions for a new instance. For classification, the predicted class is usually determined by a majority vote of the neighbors, while for regression, the predicted value is the average of the neighbors' values. k-NN is simple, effective, and requires no explicit training phase, but its performance depends heavily on the choice of 'k' and the distance metric used.